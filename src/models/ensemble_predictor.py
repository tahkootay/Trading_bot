#!/usr/bin/env python3
"""
–ú–æ–¥—É–ª—å —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∞–Ω—Å–∞–º–±–ª–µ–º ML-–º–æ–¥–µ–ª–µ–π –¥–ª—è live —Ç–æ—Ä–≥–æ–≤–ª–∏
–°–æ–≥–ª–∞—Å–Ω–æ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏: RF, LightGBM, XGBoost, CatBoost + Logistic Regression –º–µ—Ç–∞–º–æ–¥–µ–ª—å
"""

import os
import joblib
import numpy as np
import pandas as pd
from pathlib import Path
from typing import Dict, Any, Optional, Tuple, Union
import logging
import warnings
from datetime import datetime


# –ü–æ–¥–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π
warnings.filterwarnings('ignore')


class EnsemblePredictor:
    """–ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω—Å–∞–º–±–ª—è –º–æ–¥–µ–ª–µ–π."""
    
    def __init__(self, models_dir: str = "models/ensemble_live", use_latest: bool = True):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω—Å–∞–º–±–ª—è –º–æ–¥–µ–ª–µ–π.
        
        Args:
            models_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –º–æ–¥–µ–ª—è–º–∏
            use_latest: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–æ—Å–ª–µ–¥–Ω—é—é –≤–µ—Ä—Å–∏—é –º–æ–¥–µ–ª–µ–π
        """
        self.models_dir = Path(models_dir)
        self.use_latest = use_latest
        
        # –ú–æ–¥–µ–ª–∏
        self.base_models = {}
        self.meta_model = None
        self.scaler = None
        self.feature_names = []
        
        # –°—Ç–∞—Ç—É—Å –∑–∞–≥—Ä—É–∑–∫–∏
        self.models_loaded = False
        self.models_info = {}
        
        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
        self.logger = logging.getLogger(__name__)
        
        # –ê–≤—Ç–æ–∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π
        self.load_models()
    
    def _find_models_directory(self) -> Optional[Path]:
        """–ü–æ–∏—Å–∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –º–æ–¥–µ–ª—è–º–∏."""
        if not self.models_dir.exists():
            self.logger.error(f"Models directory not found: {self.models_dir}")
            return None
        
        if self.use_latest:
            latest_link = self.models_dir / "latest"
            if latest_link.exists():
                if latest_link.is_symlink():
                    target_dir = latest_link.resolve()
                    if target_dir.exists():
                        return target_dir
                elif latest_link.is_dir():
                    return latest_link
            
            # –ï—Å–ª–∏ –Ω–µ—Ç —Å—Å—ã–ª–∫–∏ latest, –∏—â–µ–º —Å–∞–º—É—é –Ω–æ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
            subdirs = [d for d in self.models_dir.iterdir() if d.is_dir() and d.name != "latest"]
            if subdirs:
                # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∏–º–µ–Ω–∏ (–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è —Ñ–æ—Ä–º–∞—Ç YYYYMMDD_HHMMSS)
                subdirs.sort(key=lambda x: x.name, reverse=True)
                return subdirs[0]
        
        return self.models_dir
    
    def load_models(self) -> bool:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π –∞–Ω—Å–∞–º–±–ª—è."""
        try:
            models_path = self._find_models_directory()
            if models_path is None:
                return False
            
            self.logger.info(f"Loading models from: {models_path}")
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–∂–∏–¥–∞–µ–º—ã–µ —Ñ–∞–π–ª—ã –º–æ–¥–µ–ª–µ–π
            model_files = {
                'random_forest': 'random_forest_intraday.joblib',
                'lightgbm': 'lightgbm_intraday.joblib', 
                'gradient_boosting': 'gradient_boosting_intraday.joblib',  # fallback –¥–ª—è LightGBM
                'xgboost': 'xgboost_intraday.joblib',
                'catboost': 'catboost_intraday.joblib'
            }
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑–æ–≤—ã–µ –º–æ–¥–µ–ª–∏
            for model_name, filename in model_files.items():
                model_path = models_path / filename
                if model_path.exists():
                    try:
                        model = joblib.load(model_path)
                        self.base_models[model_name] = model
                        self.logger.info(f"‚úÖ Loaded {model_name}")
                    except Exception as e:
                        self.logger.warning(f"Failed to load {model_name}: {e}")
            
            if not self.base_models:
                self.logger.error("No base models loaded!")
                return False
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–µ—Ç–∞–º–æ–¥–µ–ª—å
            meta_path = models_path / "meta_intraday.joblib"
            if meta_path.exists():
                try:
                    self.meta_model = joblib.load(meta_path)
                    self.logger.info("‚úÖ Loaded meta model")
                except Exception as e:
                    self.logger.error(f"Failed to load meta model: {e}")
                    return False
            else:
                self.logger.error("Meta model not found!")
                return False
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–∫–µ–π–ª–µ—Ä
            scaler_path = models_path / "scaler.joblib"
            if scaler_path.exists():
                try:
                    self.scaler = joblib.load(scaler_path)
                    self.logger.info("‚úÖ Loaded scaler")
                except Exception as e:
                    self.logger.warning(f"Failed to load scaler: {e}")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            features_path = models_path / "feature_names.joblib"
            if features_path.exists():
                try:
                    self.feature_names = joblib.load(features_path)
                    self.logger.info(f"‚úÖ Loaded {len(self.feature_names)} feature names")
                except Exception as e:
                    self.logger.warning(f"Failed to load feature names: {e}")
            
            self.models_loaded = True
            self.models_info = {
                'models_path': str(models_path),
                'base_models': list(self.base_models.keys()),
                'has_meta_model': self.meta_model is not None,
                'has_scaler': self.scaler is not None,
                'feature_count': len(self.feature_names),
                'loaded_at': datetime.now().isoformat()
            }
            
            self.logger.info("üéâ All models loaded successfully!")
            return True
            
        except Exception as e:
            self.logger.error(f"Error loading models: {e}")
            return False
    
    def _prepare_features(self, features: Union[np.ndarray, pd.DataFrame]) -> Optional[np.ndarray]:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è."""
        try:
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ numpy array
            if isinstance(features, pd.DataFrame):
                if self.feature_names:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
                    available_features = [col for col in self.feature_names if col in features.columns]
                    if len(available_features) != len(self.feature_names):
                        self.logger.warning(f"Missing features: {set(self.feature_names) - set(available_features)}")
                    features_array = features[available_features].values
                else:
                    # –ò—Å–∫–ª—é—á–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
                    exclude_cols = ['timestamp', 'open', 'high', 'low', 'close', 'volume', 'confirm']
                    feature_cols = [col for col in features.columns if col not in exclude_cols]
                    features_array = features[feature_cols].values
            else:
                features_array = features
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å
            if len(features_array.shape) == 1:
                features_array = features_array.reshape(1, -1)
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º —Å–∫–µ–π–ª–µ—Ä –µ—Å–ª–∏ –µ—Å—Ç—å
            if self.scaler is not None:
                features_array = self.scaler.transform(features_array)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ NaN –∏ Inf
            if np.isnan(features_array).any() or np.isinf(features_array).any():
                self.logger.error("NaN or Inf values in features")
                return None
            
            return features_array
            
        except Exception as e:
            self.logger.error(f"Error preparing features: {e}")
            return None
    
    def predict_base_models(self, features: Union[np.ndarray, pd.DataFrame]) -> Optional[Dict[str, float]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –æ—Ç –≤—Å–µ—Ö –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π."""
        if not self.models_loaded:
            self.logger.error("Models not loaded!")
            return None
        
        prepared_features = self._prepare_features(features)
        if prepared_features is None:
            return None
        
        try:
            base_predictions = {}
            
            for model_name, model in self.base_models.items():
                try:
                    # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Å–∞ 1 (BUY)
                    pred_proba = model.predict_proba(prepared_features)
                    if len(pred_proba.shape) == 2 and pred_proba.shape[1] >= 2:
                        probability = pred_proba[0, 1]  # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Å–∞ 1
                    else:
                        probability = pred_proba[0]
                    
                    base_predictions[model_name] = float(probability)
                    
                except Exception as e:
                    self.logger.error(f"Error predicting with {model_name}: {e}")
                    continue
            
            return base_predictions if base_predictions else None
            
        except Exception as e:
            self.logger.error(f"Error in base models prediction: {e}")
            return None
    
    def predict_ensemble(self, features: Union[np.ndarray, pd.DataFrame]) -> Optional[Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∞–Ω—Å–∞–º–±–ª—è —á–µ—Ä–µ–∑ –º–µ—Ç–∞–º–æ–¥–µ–ª—å.
        
        Returns:
            Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏: final_signal, final_probability, base_predictions
        """
        if not self.models_loaded or self.meta_model is None:
            self.logger.error("Models or meta-model not loaded!")
            return None
        
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π
        base_predictions = self.predict_base_models(features)
        if base_predictions is None:
            return None
        
        try:
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –º–µ—Ç–∞–º–æ–¥–µ–ª–∏
            # –í–∞–∂–Ω–æ: –ø–æ—Ä—è–¥–æ–∫ –¥–æ–ª–∂–µ–Ω —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –æ–±—É—á–µ–Ω–∏—é
            expected_models = ['random_forest', 'lightgbm', 'xgboost', 'catboost']
            if 'lightgbm' not in base_predictions and 'gradient_boosting' in base_predictions:
                expected_models = ['random_forest', 'gradient_boosting', 'xgboost', 'catboost']
            
            meta_features = []
            for model_name in expected_models:
                if model_name in base_predictions:
                    meta_features.append(base_predictions[model_name])
                else:
                    self.logger.warning(f"Missing prediction from {model_name}")
                    meta_features.append(0.5)  # –ù–µ–π—Ç—Ä–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
            
            meta_features_array = np.array([meta_features])
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –º–µ—Ç–∞–º–æ–¥–µ–ª–∏
            final_probability = self.meta_model.predict_proba(meta_features_array)[0, 1]
            final_signal = self.meta_model.predict(meta_features_array)[0]
            
            return {
                'final_signal': int(final_signal),
                'final_probability': float(final_probability),
                'signal_strength': 'STRONG' if abs(final_probability - 0.5) > 0.3 else 'WEAK',
                'base_predictions': base_predictions,
                'meta_features': meta_features,
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"Error in ensemble prediction: {e}")
            return None
    
    def get_models_info(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö."""
        return self.models_info.copy()
    
    def is_ready(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç–µ–ª—è."""
        return (
            self.models_loaded and 
            len(self.base_models) > 0 and 
            self.meta_model is not None
        )
    
    def get_prediction_summary(self, prediction_result: Dict[str, Any]) -> str:
        """–§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∫—Ä–∞—Ç–∫–æ–π —Å–≤–æ–¥–∫–∏ –ø–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—é."""
        if not prediction_result:
            return "No prediction available"
        
        signal = "BUY" if prediction_result['final_signal'] == 1 else "HOLD/SELL"
        prob = prediction_result['final_probability']
        strength = prediction_result['signal_strength']
        
        summary = f"Signal: {signal} | Probability: {prob:.3f} | Strength: {strength}"
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö
        base_preds = prediction_result.get('base_predictions', {})
        if base_preds:
            base_summary = " | Base: " + ", ".join([f"{k}: {v:.3f}" for k, v in base_preds.items()])
            summary += base_summary
        
        return summary


class ModelPerformanceTracker:
    """–¢—Ä–µ–∫–µ—Ä –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π –≤ live —Ä–µ–∂–∏–º–µ."""
    
    def __init__(self, max_history: int = 1000):
        self.max_history = max_history
        self.predictions_history = []
        self.performance_stats = {}
    
    def add_prediction(self, prediction: Dict[str, Any], actual_result: Optional[bool] = None):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤ –∏—Å—Ç–æ—Ä–∏—é."""
        record = {
            'timestamp': datetime.now(),
            'prediction': prediction,
            'actual_result': actual_result
        }
        
        self.predictions_history.append(record)
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –∏—Å—Ç–æ—Ä–∏–∏
        if len(self.predictions_history) > self.max_history:
            self.predictions_history = self.predictions_history[-self.max_history:]
    
    def calculate_performance(self) -> Dict[str, Any]:
        """–†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏."""
        if not self.predictions_history:
            return {}
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –∑–∞–ø–∏—Å–∏ —Å –∏–∑–≤–µ—Å—Ç–Ω—ã–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
        validated_predictions = [
            record for record in self.predictions_history 
            if record['actual_result'] is not None
        ]
        
        if not validated_predictions:
            return {'total_predictions': len(self.predictions_history)}
        
        # –°—á–∏—Ç–∞–µ–º —Ç–æ—á–Ω–æ—Å—Ç—å
        correct = sum(
            1 for record in validated_predictions
            if (record['prediction']['final_signal'] == 1) == record['actual_result']
        )
        
        accuracy = correct / len(validated_predictions)
        
        return {
            'total_predictions': len(self.predictions_history),
            'validated_predictions': len(validated_predictions),
            'accuracy': accuracy,
            'correct_predictions': correct
        }


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
def example_usage():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∞–Ω—Å–∞–º–±–ª—è."""
    # –°–æ–∑–¥–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç–µ–ª—å
    predictor = EnsemblePredictor()
    
    if not predictor.is_ready():
        print("‚ùå Predictor not ready - models not loaded")
        return
    
    print("‚úÖ Predictor ready!")
    print(f"Models info: {predictor.get_models_info()}")
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    feature_names = predictor.feature_names
    if feature_names:
        test_features = pd.DataFrame({
            name: [np.random.normal(0, 1)] for name in feature_names
        })
    else:
        # –ï—Å–ª–∏ –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö, —Å–æ–∑–¥–∞–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –Ω–∞–±–æ—Ä
        test_features = pd.DataFrame({
            'MA5': [100.5], 'MA10': [100.3], 'MA20': [100.1],
            'RSI': [55.0], 'MACD': [0.1], 'MACD_signal': [0.05],
            'BB_position': [0.6], 'vol_change': [0.02]
        })
    
    # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
    prediction = predictor.predict_ensemble(test_features)
    if prediction:
        print(f"\nPrediction: {predictor.get_prediction_summary(prediction)}")
        print(f"Full result: {prediction}")
    else:
        print("‚ùå Failed to get prediction")


if __name__ == "__main__":
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    example_usage()